{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Journal2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GshAy9D8WFSg"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.math import l2_normalize\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omCiC2qZbwh0",
        "outputId": "713363d5-b25b-4b0f-c699-0802ae220d30"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFle7wqA2TDR"
      },
      "source": [
        "# Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD00Pz0rWQ-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b0b88e-f86c-47e1-d71d-6ca1370aed54"
      },
      "source": [
        "(xtrain,ytrain),(xtest,ytest)=imdb.load_data(num_words=5000) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrZcfeyeWRzN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819abcc8-d752-4bed-80df-ea2464e617e9"
      },
      "source": [
        "word_idx=imdb.get_word_index() #getting vocab from imdb data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqlyTCUZbe0R"
      },
      "source": [
        "maxlen=500\n",
        "vocab_size=5000\n",
        "emb_dimension=300\n",
        "xtrain=pad_sequences(xtrain,maxlen=maxlen,padding='post')\n",
        "xtest=pad_sequences(xtest,maxlen=maxlen,padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgBdMY4G2f38"
      },
      "source": [
        "# Loading Google's pretrained word2vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3YGeVpbtjcV"
      },
      "source": [
        "!wget -P download -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        "from gensim.models import KeyedVectors\n",
        "word2vec = KeyedVectors.load_word2vec_format('download/GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOgV2MYZ2isZ"
      },
      "source": [
        "# Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RKP5x7Ctm-S"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size,emb_dimension))\n",
        "for word, i in word_idx.items():\n",
        "    if word in word2vec.vocab and i<vocab_size:\n",
        "        embedding_matrix[i] = word2vec.word_vec(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv0x3UEyquaf"
      },
      "source": [
        "np.save('drive/My Drive/imdb/emb.npy',embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyNGzaYdrCee"
      },
      "source": [
        "embedding_matrix=np.load('drive/My Drive/imdb/emb.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beSSQsmyWSN8"
      },
      "source": [
        "xtrain=np.asarray(xtrain).astype('float32')\n",
        "xtest=np.asarray(xtest).astype('float32')\n",
        "ytrain=np.asarray(ytrain).astype('float32')\n",
        "ytest=np.asarray(ytest).astype('float32')\n",
        "\n",
        "train=tf.data.Dataset.from_tensor_slices((xtrain,ytrain))\n",
        "test=tf.data.Dataset.from_tensor_slices((xtest,ytest))   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hELuyGki6dAz"
      },
      "source": [
        "train=train.batch(256)\n",
        "test=test.batch(256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw5PvLC7TtwJ"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PYQN7xhLA6n"
      },
      "source": [
        "class MyModel(Model):\n",
        "\n",
        "  def __init__(self,vocab_size,emb_dimension,embedding_matrix,filters,kernel_size):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.emb=Embedding(vocab_size,emb_dimension,weights=[embedding_matrix],trainable=True)\n",
        "    #Channel 1\n",
        "    self.conv1=Conv1D(filters=filters[0], kernel_size=kernel_size[0],activation='relu',kernel_regularizer=tf.keras.regularizers.l2(l=0.01))\n",
        "    self.drop1=Dropout(0.5)\n",
        "    self.bn1=BatchNormalization()\n",
        "    self.lstm1=GRU(128)\n",
        "    #Channel 2\n",
        "    self.conv2=Conv1D(filters=filters[1], kernel_size=kernel_size[1],activation='relu',kernel_regularizer=tf.keras.regularizers.l2(l=0.01))\n",
        "    self.drop2=Dropout(0.5)\n",
        "    self.bn2=BatchNormalization()\n",
        "    self.lstm2=GRU(128)\n",
        "\n",
        "    self.drop3=Dropout(0.5)\n",
        "    #Classification Layer\n",
        "    self.dense=Dense(1,activation='sigmoid')\n",
        "\n",
        "  def call(self,input):\n",
        "    a=self.emb(input)\n",
        "    x=self.conv1(a)\n",
        "    x=self.drop1(x)\n",
        "    x=self.bn1(x)\n",
        "    x=self.lstm1(x)\n",
        "\n",
        "    y=self.conv2(a)\n",
        "    y=self.drop2(y)\n",
        "    y=self.bn2(y)\n",
        "    y=self.lstm2(y)\n",
        "\n",
        "    x=concatenate([x,y])\n",
        "    x=self.drop3(x)\n",
        "    x=self.dense(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaaG3NTag8t-"
      },
      "source": [
        "model=MyModel(vocab_size=vocab_size,emb_dimension=emb_dimension,embedding_matrix=embedding_matrix,filters=[128,64],kernel_size=[7,5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEWzgNfsunF0"
      },
      "source": [
        "train_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
        "val_acc_metric = tf.keras.metrics.BinaryAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i642WGoCp2YW"
      },
      "source": [
        "loss=tf.keras.losses.BinaryCrossentropy()\n",
        "optimizer=RMSprop(learning_rate=0.01)\n",
        "epoch_losses = []\n",
        "total_epochs=12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jZYtq9iOW00"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9rf1yXOKpdN"
      },
      "source": [
        "def model_training():\n",
        "  for epoch in range(total_epochs): \n",
        "    batch_losses=[] \n",
        "    for inputs, outputs in train:\n",
        "      with tf.GradientTape() as tape:\n",
        "        current_loss = loss(model(inputs), outputs) \n",
        "        grads=tape.gradient(current_loss, model.trainable_variables) \n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "      batch_losses.append(current_loss) \n",
        "    \n",
        "      train_acc_metric.update_state(outputs,model(inputs))\n",
        "    \n",
        "    for inputs, outputs in test:\n",
        "      val_acc_metric.update_state(outputs,model(inputs))\n",
        "  \n",
        "    train_acc = train_acc_metric.result().numpy()\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    val_acc = val_acc_metric.result().numpy()\n",
        "    val_acc_metric.reset_states()\n",
        "\n",
        "    print(\"epoch \",epoch,\", Training acc : \" , train_acc,end=\"\")\n",
        "    print(\"  Validation acc: \",val_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2gBftsu7DEO",
        "outputId": "7555c308-1543-4bfb-d49b-c05a09ca9341"
      },
      "source": [
        "model_training()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch  0 , Training acc :  0.50083894  Validation acc:  0.5000418\n",
            "epoch  1 , Training acc :  0.5000418  Validation acc:  0.5000418\n",
            "epoch  2 , Training acc :  0.5014729  Validation acc:  0.49995825\n",
            "epoch  3 , Training acc :  0.7116588  Validation acc:  0.74720794\n",
            "epoch  4 , Training acc :  0.84542793  Validation acc:  0.8225769\n",
            "epoch  5 , Training acc :  0.8708242  Validation acc:  0.8172908\n",
            "epoch  6 , Training acc :  0.8874229  Validation acc:  0.8576629\n",
            "epoch  7 , Training acc :  0.9010284  Validation acc:  0.7985605\n",
            "epoch  8 , Training acc :  0.90652716  Validation acc:  0.8479733\n",
            "epoch  9 , Training acc :  0.9176707  Validation acc:  0.8322059\n",
            "epoch  10 , Training acc :  0.91993135  Validation acc:  0.86240435\n",
            "epoch  11 , Training acc :  0.92489296  Validation acc:  0.86148757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_hVGHS-M0f0",
        "outputId": "6199e555-67c7-442a-9e4d-242d5c9fecdc"
      },
      "source": [
        "optimizer=RMSprop(learning_rate=0.005)\n",
        "total_epochs=5\n",
        "model_training()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch  0 , Training acc :  0.9573425  Validation acc:  0.87347203\n",
            "epoch  1 , Training acc :  0.9610115  Validation acc:  0.8764236\n",
            "epoch  2 , Training acc :  0.9653373  Validation acc:  0.8772378\n",
            "epoch  3 , Training acc :  0.966273  Validation acc:  0.87119436\n",
            "epoch  4 , Training acc :  0.9665122  Validation acc:  0.87695694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjhR_6eNurs_",
        "outputId": "55a46dd8-08fc-49d6-96eb-02c13e4c0818"
      },
      "source": [
        "optimizer=RMSprop(learning_rate=0.005)\n",
        "total_epochs=5\n",
        "model_training()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch  0 , Training acc :  0.97364706  Validation acc:  0.8765185\n",
            "epoch  1 , Training acc :  0.9742051  Validation acc:  0.8771543\n",
            "epoch  2 , Training acc :  0.97564006  Validation acc:  0.8772568\n",
            "epoch  3 , Training acc :  0.9764372  Validation acc:  0.87787753\n",
            "epoch  4 , Training acc :  0.9760196  Validation acc:  0.8771999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIjKn_xDYQbb"
      },
      "source": [
        "model.save_weights('drive/My Drive/Colab_files/model_100_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpFtBXN2-e5h",
        "outputId": "c8911a6f-6072-4bfe-ab53-477efba306b5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      multiple                  1500000   \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            multiple                  268928    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch multiple                  512       \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  multiple                  99072     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            multiple                  96064     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch multiple                  256       \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  multiple                  74496     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  257       \n",
            "=================================================================\n",
            "Total params: 2,039,585\n",
            "Trainable params: 2,039,201\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNxlYmeSZNx6",
        "outputId": "455dc51f-693e-4360-840d-c0df713a9faa"
      },
      "source": [
        "model(xtrain[:2,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              "array([[0.5],\n",
              "       [0.5]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIYHtzWVZVDZ"
      },
      "source": [
        "model.load_weights('drive/My Drive/Colab_files/model_100_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFAfgCvKZdBW",
        "outputId": "cd047252-3487-4f3f-998b-7bba28e1b366"
      },
      "source": [
        "metric = tf.keras.metrics.AUC()\n",
        "for inputs, outputs in test:\n",
        "  metric.update_state(outputs,model(inputs))\n",
        "auc=metric.result().numpy()\n",
        "\n",
        "metric = tf.keras.metrics.BinaryAccuracy()\n",
        "for inputs, outputs in test:\n",
        "  metric.update_state(outputs,model(inputs))\n",
        "acc=metric.result().numpy()\n",
        "\n",
        "metric = tf.keras.metrics.Precision()\n",
        "for inputs, outputs in test:\n",
        "  metric.update_state(outputs,model(inputs))\n",
        "pre=metric.result().numpy()\n",
        "\n",
        "metric = tf.keras.metrics.Recall()\n",
        "for inputs, outputs in test:\n",
        "  metric.update_state(outputs,model(inputs))\n",
        "recall=metric.result().numpy()\n",
        "\n",
        "print('AUC: ',auc)\n",
        "print('Accuracy: ',acc)\n",
        "print('Precision: ',pre)\n",
        "print('Recall: ',recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.8973719\n",
            "Accuracy:  0.8771999\n",
            "Precision:  0.8849232\n",
            "Recall:  0.8668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg3bjTv8haxr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}